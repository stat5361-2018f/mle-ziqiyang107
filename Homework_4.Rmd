---
header-includes:
   - \usepackage{amsmath}
   - \usepackage{amssymb}
   - \usepackage{bbm}
title: "Statistical Computing Homework 4, Chapter 3"
author: "Ziqi Yang"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    fig_height: 6
    fig_width: 9
    number_sections: yes
    theme: united
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 3.3.2 Many local maxima
**(a) log-likelihood**
```{r cars}
x <- c(3.91, 4.85, 2.28, 4.06, 3.70, 4.04, 5.46, 3.53, 2.28, 1.96,
       2.53, 3.88, 2.22, 3.47, 4.82, 2.46, 2.99, 2.54, 0.52)
log_cos <- function(theta) {
  sum( log(1 - cos(x - theta)) ) - length(x)*log(2*pi)
}
log_cos.plottable <- function(x) {return(sapply(x, log_cos))}
curve(log_cos.plottable, from = -pi, to = pi)
```

**(b) Methods of moment**  
Let
\begin{align*}
\frac{1}{2\pi} \int_{0}^{2\pi} \big[ x - x\cos(x-\theta)\big] dx = \bar{X}
\end{align*}
so evetually, we have $\pi + \sin(\theta)=\bar{X}$, so MOM $\tilde{\theta}_n=\arcsin(\bar{X}-\pi)=$ `r asin(mean(x)-pi)`

**(c) Find MLE using Newton-Raphson**
```{r}
log_cos_D1 <- function(theta) {
  sum( sin(theta-x)/(1-cos(x-theta)) )
}

log_cos_D2 <- function(theta) {
  sum( 1+cos(theta-x)/(1-cos(theta-x))^2 )
}

para <- c(-2.7, 2.7);  temp <- rep(0, length(para))
for (i in 1:length(para)) {
  iter <- 0;  epsilon <- 0.001; 
  temp[i] <- para[i] - 1
  while( (iter <= 1000)&(abs(para[i]-temp[i])/(abs(temp[i])) > epsilon) ) {
    temp[i] <- para[i]
    para[i] <- para[i] - log_cos_D1(para[i])/log_cos_D2(para[i])
    if(abs(para[i]) == Inf) {break}
    iter <- iter + 1
    #print(para[i])
  }
}
print(para)
```

**We can see that if we start from -2.7 and 2.7, the Newton_Raphson algorithm will give us the similar result with the initial values.**  

**(d)**
```{r}
para <- seq(-pi, pi, length.out = 200);  temp <- rep(0, length(para))
for (i in 1:length(para)) {
  iter <- 0;  epsilon <- 0.001; 
  temp[i] <- para[i] - 1
  while( (iter <= 1000)&(abs(para[i]-temp[i])/(abs(temp[i])) > epsilon) ) {
    temp[i] <- para[i]
    para[i] <- para[i] - log_cos_D1(para[i])/log_cos_D2(para[i])
    if(abs(para[i]) == Inf) {break}
    iter <- iter + 1
    #print(para[i])
  }
}
print(para)
#par(pty="s")
curve(log_cos.plottable, from = -pi, to = pi, xlab="theta")
## Allow a second plot on the same graph
par(new=TRUE)

## Plot the second plot and put axis scale on right
plot(seq(-pi, pi, length.out = 200), para, pch=1,  xlab="", ylab="", 
    axes=FALSE, type="b", col="red")

## a little farther out (line=4) to make room for labels
mtext("MLE",side=3,col="red",line=4) 
axis(4, ylim=c(-4,4), col="red",col.axis="red",las=1)


## Add Legend
legend("topleft",legend=c("Log-likelihood","MLE by Newton-Raphson"),
  text.col=c("black","red"),pch=c(16,15),col=c("black","red"))
#par(pty="m")
```

# 3.3.3 Modeling beetle data

```{r}
beet <- data.frame(
    days    = c(0,  8,  28,  41,  63,  69,   97, 117,  135,  154),
    beetles = c(2, 47, 192, 256, 768, 896, 1120, 896, 1184, 1024))

growth <- function(x) {
  k <- x[1]; r <- x[2]
  k*beet$beetles[1]/(beet$beetles[1] + (k-beet$beetles[1])*exp(-r*beet$days))
}

growth.contour <- function(k,r) {
  k*beet$beetles[1]/(beet$beetles[1] + (k-beet$beetles[1])*exp(-r*beet$days))
}
growth.error <- function(k, r) {
  sum( (beet$beetles - growth.contour(k, r))^2 )
}
```

**Plot the contour plot to visually check:**  

```{r, echo=FALSE}
k <- seq(0,1500,length.out = 1e4)
r <- seq(0,1,length.out = 100)
z <- outer(k, r, FUN = Vectorize(growth.error))
contour(k, r, z)
```



## Gauss-Newton method
```{r}

```

## Multivariate method based on log-normal model MLE

**(a) Use self method: Steepest Descent(Gradient Descent)**  
```{r}


```


**(b) Validate using R function optim: use L-BFGS-B method**  
```{r}
growth.error.optim <- function(x) {
  sum( (beet$beetles - growth(x))^2 )
}
optim(c(1, 1), growth.error.optim, lower=c(0,0), upper=c(Inf, 1), method = "L-BFGS-B")
```









